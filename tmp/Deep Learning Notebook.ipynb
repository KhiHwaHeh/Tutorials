{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ဒီလိုင်းက matplotlib graph တွေကို jupyter notebook အတွင်းမှာ ပြနိုင်အောင်လို့  \n",
    "# ပုံမှန်အားဖြင့်က jupyter notebook ရဲ့ အပေါ်ဆုံးမှာ ရေးထည့်ထားလေ့ရှိတယ်။  \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Error\n",
    "\n",
    "မနေ့က Error Function ကို မိတ်ဆက်ပေးခဲ့တယ်။ နာမည်အကြီးဆုံး error တွက်တဲ့ function ကို ပြောပါဆိုရင်  \n",
    "\"Mean Squared Error\" လို့ပဲ ဆရာ ပြောရလိမ့်မယ်။  \n",
    "\n",
    "# $E = \\frac{1}{2}\\sum_{k}(y_k-t_k)^2 $\n",
    "\n",
    "ဒီနေရာမှာ $y_k$ က neural network ရဲ့ output ဖြစ်ပြီးတော့၊ $t_k$ က reference data ဖြစ်တယ်။  \n",
    "\n",
    "ဥပမာ။ ။ ကျွန်တော်တို့က \"သုည\" ကနေ \"ကိုး\" ဂဏန်းကို handwriting recognition လုပ်နေတယ်လို့ ဆိုကြပါစို့\n",
    "\n",
    "y = \\[0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0\\]  \n",
    "t = \\[0, 0, 1, 0, 0, 0, 0, 0, 0, 0\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Mean_Squared_Error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]  \n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "Mean_Squared_Error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5475"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.5]  \n",
    "\n",
    "Mean_Squared_Error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy Error\n",
    "\n",
    "Mean Squared Error လိုပဲ နောက်ထပ် သိထားသင့်တဲ့ error ကို တွက်ချက်တဲ့ formula က \"Cross Entropy Error\" ပါ။  \n",
    "# $E = -\\sum_{k}t_k \\ logy_k  $  \n",
    "\n",
    "ဒီနေရာမှာ သုံးထားတဲ့ log က natural logrithm ဖြစ်ပြီးတော့ approximately equal to 2.718281828459  \n",
    "python code အနေနဲ့ ရေးပြပါ ဆိုရင်  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_Entropy_Error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))\n",
    "\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]  \n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cross_Entropy_Error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model output prediction ရဲ့ တန်ဖိုးတွေကို ပြောင်းပြီးတော့ တွက်ခိုင်းကြည့်ရအောင်"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.15, 0.1, 0.6, 0.1, 0.6, 0.0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cross_Entropy_Error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Batch Learning  \n",
    "\n",
    "Machine Learning မှာ model ရဲ့ output (i.e. y) နဲ့ training data ထဲမှာရှိနေတဲ့ မှန်ကန်တဲ့အဖြေ (i.e. t) ကို Error Function တစ်ခုခုကို တိုက်စစ်ရင်း learning လုပ်တာ။ Neural Network မော်ဒယ်ရဲ့ weight တွေကို update လုပ်တာ။  \n",
    "\n",
    "မော်ဒယ်ကနေ ထွက်လာသမျှ y ကို မှန်ကန်တဲ့အဖြေ t နဲ့ တိုက်စစ်ဖို့လိုအပ်ပေမဲ့၊ လက်တွေ့မှာက တပြိုင်တည်းမှာ အားလုံးကို တိုက်စစ်ဖို့က မဖြစ်နိုင် တဲ့ အခြေအနေတွေရှိတယ်။ အထူးသဖြင့် training data က တအားများတဲ့ အခါမှာ။ အဲဒါကြောင့် \"Mini-Batch Learning\" ဆိုတဲ့ ပုံစံနဲ့ learning လုပ်ပြီး၊ မော်ဒယ်ကို ပိုကောင်းအောင် ပြင်ပြင်သွားတယ်။    \n",
    "\n",
    "အထက်မှာ သင်ပေးခဲ့တဲ့ Cross Entropy Error ကို Mini-Batch Learning လုပ်တဲ့ ကိစ္စကို ဖော်မြူလာနဲ့ ချရေးရရင် အောက်ပါအတိုင်း ဖြစ်လိမ့်မယ်။  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $E = -\\frac{1}{n}\\sum_{n}\\sum_{k}t_nk \\ logy_{nk}  $  \n",
    "\n",
    "အဲဒီအတွက်က Python coding လုပ်တဲ့ အခါမှာ training data ထဲက အသုတ်လိုက်၊ အသုတ်လိုက် ဆွဲယူဖို့အတွက်က np.random.choice(10000, 10) ဆိုတဲ့ ပုံစံမျိုးနဲ့ ရေးတယ်။   \n",
    "\n",
    "Cross Entropy Error တွက်တဲ့ အပိုင်းကို batch size (တစ်ခါကို ဘယ်လောက်တွက်ပါဆိုတဲ့ ဆိုက်) နဲ့ တွက်တဲ့ ပုံစံမျိုး ပရိုဂရမ်ရေးကြည့်မယ်ဆိုရင်  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#batch_size ကိုကြိုသတ်မှတ်ထားပြီးတော့\n",
    "\n",
    "def Cross_Entropy_Error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arrange(batch_size), t])) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent \n",
    "\n",
    "Gradient descent ဆိုတာကို သိဖိုလိုအပ်တယ်။  \n",
    "Theory ကိုအလွယ် ရှင်းပြရရင် local minimum value ကို ပေးထားတဲ့ function ပေါ်မူတည်ပြီး တဖြေးဖြေးချင်း အတိုး၊ အလျှော့လုပ်ပြီးတော့ ရှာတဲ့ algorithm ပါ။ လွယ်တဲ့ Quadratic equation တစ်ခုရဲ့ graph ကို ထုတ်ပြီးတော့ Gradient descent ရဲ့ အလုပ်လုပ်ပုံကို စဉ်းစားကြည့်ရအောင်။    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_quad = [n/10 for n in range(0, 100)]\n",
    "y_quad = [(n-4)**2+5 for n in x_quad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Plotting Quadratic Equation')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAG5CAYAAAAgWSjQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzs3Xt8z2Xjx/H3ZSc2S5SccgqJIm5LqluEVIRCpVaJauVW6e5A5aa6S7SIWiJKKNItx3THnQqR5JQiySFDzswcZ6fr98f3yw8N2+y763t4PR+PPbZ9vqf3Nq33ruv6XB9jrRUAAADcKeI6AAAAQKijkAEAADhGIQMAAHCMQgYAAOAYhQwAAMAxChkAAIBjFDIgyBhj5hhjHirA5xtujOlTUM/nkjHmAWPM/AJ+zi+NMZ0L8jkLmzHmoDHmEtc5gFBGIQMCkDFmozHmiPd/pDuMMR8aY4rn8TmqGGOsMSb8hGN/KSzW2ketta8UVPZTMkQZY/obYzZ5v561xphnjDHGF693rowxLxljPj7xmLX2FmvtmHw8lzXGHPL+DI+99Sy4tKd93b8UdmttcWvtBl+/NoDTo5ABgauNtba4pL9JukrSvxznyY+JkppLaiUpVtJ9kh6RNKiwg5xYTAvRld4ydOwt0UEGAH6AQgYEOGvtn5K+lHTFqbcZY4oYY/5ljEk2xuw0xow1xpTw3jzP+36fd3TmGknDJV3j/Xyf9zlGG2Ne9X7c1BizxRjztPf5thljupzwehcYYz43xuw3xiw2xrx6uilCY0xzSS0ldbDWrrTWZlprf5B0r6Qex6bQvKOBLU543EmjVMaYicaY7caYVGPMPGPM5afkme7N86OkaqdksMaY7saYtZLWeo+9ZYzZ7H3MUmNMY+/xmyW9IOku7/dnhff4SSNOxpiHjTGrjTEHjDG/GmP+drqf3ekYY4p5v+8p3ud41hiz5ZTc1U/4/MSfUUljzAxjzC7v42cYYy723tZPUmNJ73i/hndOfT5jTAnvv5Nd3n83/zLGFPHe9oAxZr4xZqD3uf8wxtyS168PwF9RyIAAZ4ypKM8I0/Icbn7A+3aDpEskFZf0jve2673vz/eOziyU9Kikhd7Pzz/NS5aVVEJSBUkPShpqjCnpvW2opEPe+3T2vp3OjZIWWWs3n3jQWrtI0hZ5Rs5y40tJNSRdJGmZpHEn3DZUUpqkcpK6et9OdZukqyXV9n6+WFI9SaUkjZc00RhT1Fo7U9Jrkj71fn+uPPWJjDF3SHpJ0v2SzpPUVtKeXH4dJ3pRnvJYTdJNOvP38VRFJH0oqbKkSpKOyPszt9b2lvSdpMe8X8NjOTw+SZ6f7yWSmni/li4n3H61pDWSLpSUKOkDf51iBgIJhQwIXFO9o1jzJc2VpyycKl7Sm9baDdbag5Kel9TpHKfnMiT921qbYa39r6SDkmoaY8IkdZD0orX2sLX2V0lnWlt1oaRtp7ltm6TSuQljrR1lrT1grT0qTxm60jvKcyxPX2vtIWvtytPk6W+t3WutPeJ9vo+ttXu8I3aDJEVJqpmbLJIekpRorV1sPdZZa5PPcP9lxph9J7zd5D1+p6R+3lybJb2dy9eXN/sk78/ggKR+8hSrs/J+z+6S9Lz3e7pRnunj+064W7K1dqS1Nkue72c5SWVymw9AzlysmQBQMG6z1s4+y33KSzqxECTL89/9ufwPdI+1NvOEzw/LM/JW2vvcJ454nTT6dYrd8oxs5aScpF1nC+ItEP0k3eF9/WzvTRdKKpZDnpzK0UkZjTFPy1Osykuy8ox0XXi2LF4VJa3P5X0l6W/W2nU5HC+vs+fOkTEmWtJgSTdLOjZyGWuMCfOWqDO5UFKk/vpvpsIJn28/9oG19rB3cCxPJ5QA+CtGyIDgtlWeqatjKknKlLRDnrJxqpyO5dYu73NffMKxime4/2xJV3unXI8zxjT05jy2xu2QpOgT7lL2hI/vkdROUgt5ptmqHHuaE/Kc+PyVcshx/Gv2rhfrJc8IVUnvtG2q9/lOuu9pbNYp69TyaZvOnPuwTv89eVqeEb2rrbXn6f+npnPzNeyWZwT01H8zf+YuNoD8opABwe0TSf80xlQ1nm0xjq2BypSnsGTLs1bomB2SLjbGROb1hbyjL5MlvWSMiTbGXCbP+qPT3X+2pK8lTTLGXG6MCTPGNJJnDdhYa+0a711/kmeaNcIYEyep4wlPEyvpqDzrtKJ1wrRtDnlq6+xrsWLlKXG7JIUbY/rKM0J2zA5JVY4tcs/B+5KeMcY0MB7VjTGVT3PfM/mPpOe9C/QvlvT4Kbf/JOke7/fsZp08JRkrz7qxfcaYUvKsRzvRDp38Mz/O+z37j6R+xphYb/anJH2c0/0BFBwKGRDcRkn6SJ7Rpj/kWeD+uOSZbpJnum+Bd/1SI0nfSFolabsxZnc+Xu8xeUaqtntf9xN5CtPpdJD0raSZ3mwLvR8nnHCfPvKMOqVIelmehfbHjJVnSu1PSb9K+iGHPMW9eUbLs9j9TGbJc5LA797nTdPJU4cTve/3GGOWnfpga+1Eeb6n4yUdkDRVnpMDTmeFOXkfsiHe4y97X/8PSf+T53t5oh6S2kjaJ886wakn3DZEnuna3fJ8P2ae8ti3JHX0niWZ09q0x+UZldwgz/rE8fL8OwLgQ8bac5mhAIDTM8a8LqmstTZXZwkaY8bIs16plbU23afhAogxpqmkj621F5/tvgACEyNkAAqMMeYyY0xd73RdQ3m2xZiSh6d4SNJX8mx2CwAhw2dnWRpjisozTRLlfZ3PrLUvGmOqSpogzzD+Mkn38ZcwEDRi5ZmmLC9ppzxbJkzL7YOttRmSXvdNNADwXz6bsvRuFBhjrT1ojImQZy1CD3kWiE621k4wxgyXtMJaO8wnIQAAAAKAz6YsvZsiHvR+GuF9s5KaSfrMe3yMPLtkAwAAhCyfbgzr3bRxqaTq8lzCZL2kfSdsKrlFJ284eOJjE+Q90yomJqbBZZdd5suoAACgEPz222/KyMhQnTp1XEfxmaVLl+621ubqaiPH+LSQefe0qWeMOV+ehb21crrbaR47QtIISYqLi7NLlizxWU4AAOB7f/zxhy677DINHDhQjz9+6vZ6wcMYk+uraxxTKJdOstbuM8bMkdRI0vnGmHDvKNnF8uwkDgAAglzVqlWVnJys2NhY11H8js/WkBljSntHxmSMKSbPpU1Wy7MJ5LGdtjsrD2dgAQCAwJSZ6VmtVLZsWcXExDhO4398uQ9ZOUnfGmN+lrRY0lfW2hnyXCfuKWPMOkkXSPrAhxkAAIAf6NWrl1q0aKGsrLNd4z40+WzK0lr7s6T6ORzfIKmhr14XAAD4l/379+v9999X69atFRYW5jqOX2KnfgAA4FOjRo3S/v379dRTT7mO4rcoZAAAwGcyMzP11ltv6e9//7vi4uJcx/FbFDIAAOAzU6dO1caNGxkdOwsKGQAA8JmbbrpJ7733ntq2bes6il8rlH3IAABAaIqNjVVCQoLrGH6PETIAAOATL7zwgsaPH+86RkCgkAEAgAKXnJysxMRE/fTTT66jBAQKGQAAKHBvvfWWjDFBfc3KgkQhAwAABWrfvn0aOXKkOnXqpIoVK7qOExAoZAAAoEC99957OnjwoJ5++mnXUQIGhQwAABSoWrVq6fHHH1e9evVcRwkYxlrrOsNZxcXF2SVLlriOAQAAcFbGmKXW2jxdloARMgAAUCCstRo+fLhSUlJcRwk4FDIAAFAg/ve//6lbt26aPn266ygBh0IGAAAKxMCBA1W+fHndfffdrqMEHAoZAAA4Zz/99JNmz56tHj16KDIy0nWcgEMhAwAA52zQoEEqXrw4163MJwoZAAA4J9nZ2dq3b58efvhhnX/++a7jBKRw1wEAAEBgK1KkiD7//HNlZWW5jhKwGCEDAAD5tn//fiUnJ0uSwsLCHKcJXBQyAACQb++++66qV6+uzZs3u44S0ChkAAAgX9LS0jRkyBA1b96ci4ifIwoZAADIl48++kg7duxQz549XUcJeBQyAACQZ1lZWXrjjTfUoEED3XDDDa7jBDzOsgQAAHm2fPly/fHHHxo/fryMMa7jBDwKGQAAyLO4uDht2LBB5cuXdx0lKDBlCQAA8iQtLU2SVLFiRba6KCAUMgAAkCft27dXfHy86xhBhUIGAABy7eeff9aXX36p2rVru44SVChkAAAg19544w3FxMSoW7durqMEFQoZAADIleTkZH3yySdKSEhQqVKlXMcJKhQyAACQK2+//baMMXryySddRwk6bHsBAABypW/fvmrWrJkqVarkOkrQYYQMAADkSokSJdS6dWvXMYIShQwAAJzR/v37df3112vevHmuowQtChkAADij4cOH67vvvlN0dLTrKEGLQgYAAE4rLS1NgwcP1o033qi4uDjXcYIWi/oBAMBpjR49Wtu3b9f48eNdRwlqjJABAIAcZWZmKjExUVdffbWaNm3qOk5QY4QMAACc1osvvqiKFSvKGOM6SlCjkAEAgByFh4erc+fOrmOEBKYsAQDAX8yePVsDBw7U0aNHXUcJCRQyAABwEmut+vbtq6FDhyosLMx1nJDAlCUAADjJnDlztHDhQg0dOlTh4VSFwsAIGQAAOMmrr76qsmXLqmvXrq6jhAxqLwAAOG7hwoX65ptvNGjQIBUtWtR1nJDBCBkAADguMjJS7dq10yOPPOI6SkhhhAwAABzXoEEDTZ061XWMkMMIGQAAkOS5TNLWrVtdxwhJFDIAAKBVq1apS5cuGjZsmOsoIYlCBgAA1L9/f0VHR6tHjx6uo4QkChkAACFu/fr1+uSTT9StWzddeOGFruOEJAoZAAAhbsCAAYqIiNDTTz/tOkrIopABABDCrLXKzMxUQkKCypUr5zpOyGLbCwAAQpgxRh9++KGsta6jhDSfjZAZYyoaY741xqw2xqwyxvTwHn/JGPOnMeYn71srX2UAAACnt337dv3888+SPMUM7vhyyjJT0tPW2lqSGknqboyp7b1tsLW2nvftvz7MAAAATmPAgAGKi4vTzp07XUcJeT6bsrTWbpO0zfvxAWPMakkVfPV6AAAg97Zt26b33ntP9957ry666CLXcUJeoSzqN8ZUkVRf0iLvoceMMT8bY0YZY0qe5jEJxpglxpglu3btKoyYAACEjIEDByojI0O9e/d2HQUqhEJmjCkuaZKkJ621+yUNk1RNUj15RtAG5fQ4a+0Ia22ctTaudOnSvo4JAEDI2LFjh4YNG6b4+HhVq1bNdRzIx4XMGBMhTxkbZ62dLEnW2h3W2ixrbbakkZIa+jIDAAA42dKlSxUREcHomB/x2Roy4zld4wNJq621b55wvJx3fZkk3S5ppa8yAACAv2rVqpW2bt2qmJgY11Hg5ct9yK6TdJ+kX4wxP3mPvSDpbmNMPUlW0kZJj/gwAwAAOMHatWtVvXp1ypif8eVZlvMl5bSpCdtcAADgwO7du1W/fn316NFD/fr1cx0HJ+DSSQAAhIjBgwfr8OHDuueee1xHwSkoZAAAhIC9e/cqKSlJHTt21OWXX+46Dk5BIQMAIAQMGjRIBw8eVN++fV1HQQ4oZAAABLmsrCxNnjxZd955p6644grXcZADX55lCQAA/EBYWJiWL1+u/fv3u46C06CQAQAQxA4ePKjIyEgVLVpURYsWdR0Hp8GUJQAAQezll19WrVq1dPjwYddRcAYUMgAAgtSOHTs0dOhQXXvttYqOjnYdB2dAIQMAIEi9/vrrSk9P58zKAEAhAwAgCG3btk3Dhg3Tvffeqxo1ariOg7OgkAEAEITGjh2rjIwM9enTx3UU5AKFDACAINSzZ08tXrxY1apVcx0FuUAhAwAgyBw9elTGGNWvX991FOQShQwAgCCSnJysiy++WDNmzHAdBXlAIQMAIIi88sor2r9/v6688krXUZAHFDIAAILE2rVrNXr0aHXr1k0VK1Z0HQd5QCEDACBIvPTSS4qKitLzzz/vOgryiEIGAEAQ2LRpkyZMmKAnnnhCZcqUcR0HecTFxQEACAKVKlXSokWLdMkll7iOgnygkAEAEOCysrIUFhamuLg411GQT0xZAgAQ4Nq1a6enn37adQycAwoZAAABbP78+friiy9YNxbgKGQAAAQoa6169+6tsmXL6rHHHnMdB+eANWQAAASor776SvPmzdPbb7+t6Oho13FwDhghAwAgQP373/9W5cqVlZCQ4DoKzhEjZAAABKhPPvlEmzZtUlRUlOsoOEcUMgAAAoy1VsYYVaxYkUskBQmmLAEACDCjRo1S8+bNtW/fPtdRUEAoZAAABJAjR47opZde0uHDh1WiRAnXcVBAmLIEACCAvPvuu9qyZYs++ugjGWNcx0EBYYQMAIAAkZqaqtdee0033XSTmjZt6joOChCFDACAAJGUlKS9e/fqtddecx0FBYwpSwAAAsSTTz6pyy67TH/7299cR0EBY4QMAIAAYK1V8eLF1bFjR9dR4AMUMgAA/NyGDRtUt25dLVmyxHUU+AiFDAAAP9e7d2+tX79e5cuXdx0FPkIhAwDAjy1evFgTJkzQU089RSELYhQyAAD8lLVWvXr10oUXXqiePXu6jgMf4ixLAAD81Jw5c/Ttt9/q7bff1nnnnec6DnyIQgYAgJ+6/vrr9cknn6h9+/auo8DHKGQAAPgha63CwsLUqVMn11FQCFhDBgCAnxg3TqpSRSpSxCoqapsee+x715FQSChkAAD4gXHjpIQEKTlZstYoI6O83n//ao0b5zoZCgOFDAAAP9C7t3T48MnHjh4NU+/ebvKgcAVEIVu3bp0yMzNdxwAAwGc2bcrbcQSXgChkqampGjVqlOsYAAD4TKVKeTuO4BIQhax48eLq06ePDhw44DoKAAA+0a+fFB198rHoaM9xBL+AKGQXX3yxdu7cqcTERNdRAADwiU6dsjRihFS5smSM5/2IEVJ8vOtkKAwBUchiYmJ09913a9CgQdq6davrOAAAFChrrZo1a6YNG17Rxo1Sdra0cSNlLJQERCGTpP79+2v48OEqW7as6ygAABSozz77TPPmzePi4SHMWGtdZziruLg4u2TJEtcxAAAocEePHlXt2rUVExOj5cuXKywszHUknCNjzFJrbVxeHhMwI2THvP/+++rQoYMCoUgCAHA2Q4cO1YYNGzRw4EDKWAgLuEJ29OhRTZ48WTNmzHAdBQCAc3L06FG9/vrruvnmm9WyZUvXceBQwE1ZZmRk6IorrpAxRr/88osiIiIcpwMAIP/WrVsnSapevbrjJCgofjVlaYypaIz51hiz2hizyhjTw3u8lDHmK2PMWu/7knl53oiICCUmJmrNmjV67733fBMeAAAfS0tLk+QpYpQx+HLKMlPS09baWpIaSepujKkt6TlJX1tra0j62vt5nrRt21Y33HCDXnrpJR06dKhAQwMAUBjuuusu3Xvvva5jwE/4rJBZa7dZa5d5Pz4gabWkCpLaSRrjvdsYSbfl9bmNMXrnnXc0efJkxcTEFFRkAAAKxezZszV9+nTVqVPHdRT4iUJZQ2aMqSJpnqQrJG2y1p5/wm0p1tq/TFsaYxIkJUhSpUqVGiQnJ5/2+bOzs1WkSMCdnwAACEGZmZmqX7++Dh06pF9//VVFixZ1HQkFzK/WkB1jjCkuaZKkJ621+3P7OGvtCGttnLU2rnTp0qe937/+9S+1b9++AJICAOB777//vlauXKmBAwdSxnCcTwuZMSZCnjI2zlo72Xt4hzGmnPf2cpJ2nstrnH/++Zo2bZpmzZp1bmEBAPCx7Oxsvf3222rSpIluv/1213HgR3w2ZWmMMfKsEdtrrX3yhONvSNpjrR1gjHlOUilrbc8zPdeZduo/evSoLr/8ckVFRWnFihUKDw8vwK8CAICClZKSotTUVFWpUsV1FPiIv01ZXifpPknNjDE/ed9aSRog6UZjzFpJN3o/z7eoqCgNHDhQv/76K9tgAAD81t69e5WVlaWSJUtSxvAXAbcxbE6stWrevLl+++03bdy4UZGRkYWYDgCAs2vXrp327t2refPmyTOJhGCVnxGyoJjfM8Zo+PDhKlKkCGUMAOB3jm1z0b9/f8oYchQUI2SnOnz4sKKjo32YCACA3MnIyFD9+vV1+PBhtrkIESE7Qnai+++/X9u3b9esWbP4KwQA4Ny7776rVatWaerUqZQxnFbQ7aZ61VVX6auvvtK0adNcRwEAhDhrrT799FO1bNlSbdu2dR0HfizopiwzMzNVr1694zsgFytWzMfpAAA4vYyMDKWkpOiiiy5yHQWFxN+2vXAiPDxcb7/9tjZu3KhBgwa5jgMACFEbN27U/v37FRERQRnDWQVdIZOkZs2aqWPHjho5cqTS09NdxwEAhJjs7Gzdc889atKkiQJhJgruBd2i/mOSkpIUFRXFNhgAgEI3btw4LVy4UB9++CEnmCFXgm4N2amysrK0bds2XXzxxQWcCgCAvzpw4IAuvfRSVapUSQsXLlSRIkE5GYUzYNuLHHTo0EEbNmzQsmXLuM4lAMDnXnnlFW3fvl3Tpk2jjCHXgv5fyv33369ffvlFw4YNcx0FABDkrLVavXq1unTpooYNG7qOgwAS9FOW1lrddNNN+vHHH7VmzRqVKVOmgNMBAPD/rLU6evQom8CGMLa9yIExRklJSTp8+LB69uzpOg4AIEjNnz9fycnJMsZQxpBnQV/IJKlmzZp65plntHTpUh06dMh1HABAkDl48KA6deqke+65x3UUBKiQKGSS1LdvXy1fvlwxMTGuowAAgsy///1v/fnnnxo4cKDrKAhQIVPIihYtqoiICO3fv1/z5s1zHQcAECR+/fVXDR48WF27dtU111zjOg4CVMgUsmO6d++uNm3aaNu2ba6jAAACnLVWjz32mGJjYzVgwADXcRDAQq6Q9e3bV2lpaXr22WddRwEABLj09HTVrFlTAwYMUOnSpV3HQQAL+m0vctKnTx+9+uqrmjNnjpo0aVJgzwsAAMC2F7n0/PPPq3LlyurevTsXHwcA5Ms777yjH374wXUMBImQLGTR0dFKSkpS+fLllZqa6joOACDArFixQk8++aRGjRrlOgqCREhOWR5jrZUxpsCfFwAQvLKysnTddddpw4YN+u2331SqVCnXkeBnmLLMI2OMkpOT9dprrykQiikAwL2RI0dq0aJFevPNNyljKDAhXcgkacqUKerdu7emTJniOgoAwM/t2LFDzz33nJo1a6b4+HjXcRBEQnrKUpIyMzN11VVXadeuXVq9erViY2N98joAgMCXnp6uwYMH67bbblPNmjVdx4GfYsoyH8LDwzV8+HBt3bpVffr0cR0HAODHIiMj1atXL8oYClzIFzJJuvrqq/Xoo48qKSlJy5Ytcx0HAOBn0tLS1LRpU3355ZeuoyBIUci8XnvtNfXo0UNVqlRxHQUA4Gf69++vuXPnKiIiwnUUBKmQX0MGAMCZrFmzRnXr1tUdd9yhjz/+2HUcBADWkBWAVatWqUmTJtq8ebPrKAAAx7Kzs/Xwww8rJiZGgwYNch0HQYxCdopixYpp8eLF6t69O3uTAUCI++9//6vvvvtOAwcOVJkyZVzHQRCjkJ3ikksu0SuvvKLPP/9cn332mes4AACHWrdurZkzZ6pLly6uoyDIsYYsB5mZmWrUqJG2bNmi1atXq2TJkoX22gAA/7Bz505ddNFFrmMgALGGrICEh4dr5MiR2r17twYPHuw6DgCgkE2dOlVVq1bVjz/+6DoKQkS46wD+qn79+po1a5YaN27sOgoAoBClpqaqe/fuqlGjhurXr+86DkIEhewMmjdvLsnzH2dUVJSKFi3qOBEAwNeef/55bd++XVOnTmXfMRQapizPIiUlRZdffrleeeUV11EAAD62YMECDRs2TE888YSuuuoq13EQQihkZ1GyZEm1aNFCiYmJWrFihes4AAAfmj9/vqpUqcIf4Sh0nGWZC3v37lXt2rVVvnx5LVq0iCFsAAhiBw4cUGxsrOsYCGCcZekjpUqV0tChQ7V8+XINHDjQdRwAQAFbsWKFfvjhB0mijMEJFvXnUocOHdSxY0f98MMPstbKGOM6EgCgAKSnp+v+++/Xnj17tH79ekVFRbmOhBBEIcuDMWPGqFixYpQxAAgir7/+un7++WdNnTqVMgZnmLLMg+joaBljlJycrClTpriOAwA4RytXrtQrr7yiTp06qV27dq7jIIRRyPKhV69eio+P17p161xHAQDkU2Zmprp27arzzz9fSUlJruMgxFHI8mHQoEGKjIzUQw89pOzsbNdxAAD51KFDB7377ru68MILXUdBiKOQ5UOFChX05ptvau7cuRo+fLjrOACAfAgPD1evXr3UsWNH11EACll+denSRS1btlTPnj21YcMG13EAALmUlZWl2267TTNmzHAdBTiOQpZPxhi9//776ty5sy644ALXcQAAuTRw4EBNmzZN+/fvdx0FOI6d+gsIe5MBgP9buXKlGjRooDZt2mjixIn83oZPsFO/I7/99psaNWqkNWvWuI4CADiNjIwMde7cWSVKlNCwYcMoY/ArFLICUKJECa1du1YPPPCAMjMzXccBAOTgs88+07JlyzR8+HCVLl3adRzgJBSyAlCuXDkNHTpUP/zwA9e6BAA/1alTJ82bN0/t27d3HQX4i1ytITPGXCTpOknlJR2RtFLSEmttoWzCFShryO68805Nnz5dS5cu1RVXXOE6EgBA0tGjR7VlyxZVq1bNdRSEiAJfQ2aMucEYM0vSF5JukVROUm1J/5L0izHmZWPMefkNHEyMMXr33XdVokQJJSYmuo4DAPB6+eWXVbduXW3evNl1FOC0znZx8VaSHrbWbjr1BmNMuKRbJd0oaVIOt4/y3r7TWnuF99hLkh6WtMt7txestf/Nd3o/U7p0aX377beqUaOG6ygAAEkLFy7U66+/rgceeEAVK1Z0HQc4LZ9te2GMuV7SQUljTylkB621eVpoFQhTlqdKSUnRtm3bVLt2bddRACAkHThwQPXq1VN2drZWrFih885jQgeFw2fbXhhjPjLGlDjh8yrGmK/P9Bhr7TxJe/MSJpi0a9dObdu21cGDB11HAYCAF2EiAAAgAElEQVSQ9M9//lN//PGHxo4dSxmD38vtWZbzJS0yxrQyxjws6X+ShuTzNR8zxvxsjBlljCmZz+fwe/369dOGDRv01FNPuY4CACEnOztbxYoV03PPPafGjRu7jgOcVa6nLI0xf5f0raTdkupba7fn4jFVJM04YcqyjPfxVtIrkspZa7ue5rEJkhIkqVKlSg2Sk5NzldOfPPfcc3r99dc1bdo0tW3b1nUcAAg5XEUFLvhyyvI+SaMk3S9ptKT/GmOuzGtAa+0Oa22Wd7uMkZIanuG+I6y1cdbauEDdwO/ll1/WlVdeqYceekg7d+50HQcAgp61Vo8//rgWLVokSZQxBIzcTll2kPR3a+0n1trnJT0qTzHLE2NMuRM+vV2e/cyCVlRUlMaNG6drrrlG2dmFsmUbAIS0ESNG6J133tEPP/zgOgqQJ/k+y9IYE2mtTT/D7Z9IairpQkk7JL3o/byePFOWGyU9Yq3ddrbXCsSzLAEAhWvt2rWqV6+err32Ws2aNUtFinAxGrjhi41h/2WMKZXTbdbadGNMM2PMrae5/W5rbTlrbYS19mJr7QfW2vustXWstXWttW1zU8aCxdatW9WmTRv9/vvvrqMAQNBJT09XfHy8IiMjNXr0aMoYAs7ZNob9RdLnxpg0Scvk2dC1qKQa8ox0zZb0mk8TBglrrRYuXKi7775bCxcuVGRkpOtIABA0PvjgAy1evFgTJ05UhQoVXMcB8uxsf0J0tNZeJ2mWpFWSwiTtl/SxpIbW2n9aa3ed6QngUaFCBX3wwQdatmyZevfu7ToOAASVhIQETZ8+XR07dnQdBciXM64hM8b8Ks81LKdLuuHU2621hbLxazCtIfvHP/6hYcOGadasWWrZsqXrOAAQ0Pbs2aPMzEyVKVPGdRTguPysITtbIXtCUjdJl0j688SbJFlr7SX5CZpXwVTIjhw5ori4OJ133nn6/vvvOSUbAPLJWqvbbrtNy5cv1++//66iRYu6jgRI8sGifmvt29baWpJGWWsvOeGtamGVsWBTrFgxTZ8+XTNnztT4leNVZUgVFXm5iKoMqaJxv4xzHQ8A/N64cVKVKlKRItL06W/p+uvfo4wh4OXqNBRrbTdfBwkl1apV04xNM5QwPUHJqcmyskpOTVbC5wmUMgA4g3HjpIQEyXPxFiOpiqZMuVnj+NWJAJfvfcgKUzBNWR5TZUgVJaf+9XJQlUtU1sYnNxZ+IAAIAFWqHCtjJ6tcWdq4sbDTADnz2aWTUPA2pW7K03EAgLTpNL8iT3ccCBQUMkcqlaiUp+MAAKnSaX5Fnu44ECgoZI70a95P0RHRJx2LNJHq17yfo0QA4N/WrVunmJjXVKzYydcGjo6W+vGrEwGOQuZIfJ14jWgzQpVLVJaRUfGs4nq14auKrxPvOhoA+J20tDTdeeed2rZtoAYM2KvKlSVjPGvHRoyQ4vnViQDHon4/Y61VZmamIiIiXEcBAL/x+OOP65133tH06dPVpk0b13GAM8rPov6zXcsShchaqwceeEBhYWEaNWqU6zgA4BcmTZqkd955R0899RRlDEGLKUs/YoxR5cqV9eGHH+qjjz5yHQcAnLPWatCgQWrYsKH69+/vOg7gM0xZ+pmsrCw1b95cixcv1uLFi1W7dm3XkQDAqUOHDik1NVXly5d3HQXIFfYhCwJhYWEaP368YmNj1aFDBx04cMB1JABwYsyYMTp06JBiYmIoYwh6FDI/VL58eU2YMEG7d+/W6tWrXccBgEI3duxYPfDAAxo2bJjrKEChYMrSjx08eFDFixd3HQMACtUvv/yiq6++Wg0bNtTs2bMVHs75ZwgsTFkGmeLFi8taqzfeeEMLFixwHQcAfC41NVUdOnTQ+eefrwkTJlDGEDIoZH7u4MGDeu+993TnnXdq586druMAgE/16NFDGzZs0KeffqqyZcu6jgMUGgqZn4uNjdVnn32mvXv36u6771ZWVpbrSADgM3379tWYMWPUuHFj11GAQkUhCwD16tXTu+++q2+++UZ9+vRxHQcACtzGjRtlrdUll1yieK6DhBBEIQsQXbp00cMPP6zExEStW7fOdRwAKDCbN29Ww4YN9eyzz7qOAjhDIQsgSUlJmjdvnqpXr+46CgAUiCNHjqh9+/ZKS0vTQw895DoO4AyFLIBERUXp2muvlSR99dVXSklJcZwIAPLPWqtu3bppyZIl+vjjj3XZZZe5jgQ4QyELQNu2bVObNm0UHx/PIn8AAWvo0KEaM2aMXnzxRbVt29Z1HMApClkAKleunN566y19+eWX6tu3r+s4AJAvl19+ubp06cLvMUDs1B/QEhISNHLkSH322Wfq0KGD6zgAkCvp6emKjIx0HQPwGXbqDzFJSUlq1KiROnfurC1btriOAwBndeTIETVu3FiJiYmuowB+hUIWwKKiojRp0iQNHDhQFSpUcB0HAM7IWquuXbtq8eLFLOAHTkEhC3Dly5fXo48+KmOM1q5dq/T0dNeRACBHr732miZMmKD+/fuziB84BYUsSOzYsUNxcXHq1q2bAmFdIIDQMnnyZP3rX//Sfffdp549e7qOA/gdClmQKFOmjJ544gmNGjVKQ4YMcR0HAE6yd+9eNW7cWCNGjJAxxnUcwO9wlmUQyc7O1p133qkpU6ZoxowZuuWWW1xHAhDirLXHC1h2draKFGEcAMGPsyxDXJEiRTRmzBjVrVtXnTp10tq1a11HAhDC0tLS1LJlS02dOlWSKGPAGfBfR5CJiYnR9OnT9eCDD6pSpUqu4wAIUdZaPfjgg5o9e7ays7NdxwH8HoUsCFWsWFFvvvmmoqKitGfPHh05csR1JAAh5sUXX9T48ePVr18/tW/f3nUcwO9RyIJYWlqarrvuOnXu3Jm/UAEUmtGjR+uVV17Rgw8+qOeff951HCAgUMiCWNGiRfXQQw9p4sSJeuGFF1zHARAili9frubNm2vYsGGcUQnkUrjrAPCtp59+WuvXr9frr7+uatWq6eGHH3YdCUCQGzJkiI4ePaqIiAjXUYCAwQhZkDPGKCkpSbfccou6deumr7/+2nUkAEFox44datq0qVauXCljjIoWLeo6EhBQKGQhIDw8XJ9++qk6d+6sK664wnUcAEHm0KFDatu2rX788UdOIgLyiSnLEBEbG6sPPvhAkpSRkaE9e/aobNmyjlMBCHSZmZm66667tGTJEk2aNElXXXWV60hAQGKELATdd999uuGGG7Rnzx7XUQAEMGutHnnkEX3xxRcaOnSobrvtNteRgIBFIQtB3bp10x9//KE2bdro8OHDruMACFBHjhzR+vXr1adPHz366KOu4wABjWtZhqhJkybpjjvu0K233qrJkycrPJzZawC5d+walenp6YqIiGB7C+AEXMsSudahQwclJSXp888/1zPPPOM6DoAAMnnyZDVt2lQpKSmKjIykjAEFgGGRENa9e3cdOnRILVu2dB0FQID47rvvdM8996h+/fqKiopyHQcIGkxZ4rhly5bpb3/7m+sYAPzUsmXLdMMNN6hcuXJasGCBLrjgAteRAL/ElCXybdy4cWrQoIHGjh3rOgoAP7RmzRrdfPPNOv/88/XVV19RxoACRiGDJKljx45q0aKFunTpoilTpriOA8DPFClSRFWqVNFXX32lihUruo4DBB0KGSRJUVFRmjJliho2bKhOnTpp9uzZriMB8AP79++XtVY1atTQokWLdOmll7qOBAQlChmOK168uP773/+qZs2aat++vXbv3u06EgCH9u3bp+uvv17//Oc/JYmzKQEfopDhJCVLltT//vc/jR07VhdeeKHrOAAcOXTokFq3bq1ff/1VrVq1ch0HCHoUMvxF2bJlj18CZdasWfr1118dJwJQmA4fPqw2bdrohx9+0Pjx49kaBygEPitkxphRxpidxpiVJxwrZYz5yhiz1vu+pK9eH+fu6NGjeuSRR9S8eXP9/vvvruMAKATWWt11112aM2eOxowZo44dO7qOBIQEX46QjZZ08ynHnpP0tbW2hqSvvZ/DT0VFRenLL79UVlaWmjVrpvXr17uOBMDHjDHq1q2bRo0apXvvvdd1HCBk+KyQWWvnSdp7yuF2ksZ4Px4j6TZfvT4KRq1atfT1118rLS1NzZo108aNG11HAuADGRkZ+vbbbyVJrVq10gMPPOA2EBBiCnsNWRlr7TZJ8r6/6HR3NMYkGGOWGGOW7Nq1q9AC4q/q1Kmj2bNn68CBA/rwww9dxwFQwDIzM3X33XerRYsWWrNmjes4QEjy22tZWmtHSBoheS6d5DhOyKtXr56WLVumypUru44CoABlZmbqvvvu06RJkzR48GDVrFnTdSQgJBX2CNkOY0w5SfK+31nIr49zUKVKFRljtGHDBjVp0kTJycmuIwE4BxkZGerUqZMmTJigxMREPfnkk64jASGrsAvZdEmdvR93ljStkF8fBSAlJUU///yzmjRpog0bNriOAyCfJk+erEmTJunNN9/Us88+6zoOENKMtb6ZDTTGfCKpqaQLJe2Q9KKkqZL+I6mSpE2S7rDWnrrw/y/i4uLskiVLfJIT+bN8+XK1aNFC0dHR+uabb1SjRg3XkQDkkbVWixYtUqNGjVxHAYKKMWaptTYuL4/x5VmWd1try1lrI6y1F1trP7DW7rHWNrfW1vC+P2sZg3+qX7++vv32Wx09elRNmjTR2rVrXUcCkAuHDx9Wp06dtGLFChljKGOAn2CnfuRb3bp1NWfOHDVs2FBlypRxHQfAWRw6dEi33nqr/vOf/+iXX35xHQfACShkOCe1a9fW1KlTdd555+nQoUNasWKF60gAcpCSkqKWLVtq7ty5+uijj9j0FfAzFDIUmB49eujvf//78c0lAfiH3bt3q2nTplqyZIkmTpyo+Ph415EAnIJChgLz73//W5UrV9Ytt9yiadM4gRbwF7GxsapevbpmzJih9u3bu44DIAc+O8uyIHGWZeDYs2ePWrVqpaVLl+qhtx7SzIyZ2pS6SZVKVFK/5v0UX4e/zIHCsnr1apUuXVoXXnih6yhASPGrsywRmi644AJ9/fXXqnlHTb237T0lpybLyio5NVkJnydo3C/jXEcEQsLixYvVuHFjde3a1XUUALlAIUOBK168uA42PChFnHz8cMZh9f66t5tQQAj53//+p2bNmum8887T4MGDXccBkAsUMvjE5v2bczy+KXVTIScBQsuYMWPUunVrVatWTfPnz1e1atVcRwKQCxQy+ESlEpVyPH5x7MWFnAQIHWlpaXr11VfVtGlTzZs3T+XLl3cdCUAuUcjgE/2a91N0RPTJB9Ml843Rtm3b3IQCglRmZqYyMjJUtGhRzZkzR1988YXOO+8817EA5AGFDD4RXydeI9qMUOUSlWVkVLlEZT1b61ntmbNHTZs2VUZGhuuIQFA4dOiQ2rdvr4cffljWWlWoUEGRkZGuYwHIo3DXARC84uvE/2Wbi7tq3aXk5GRFRESc5lEAcmvr1q1q166dli5dqqSkJBljXEcCkE8UMhSqBg0aqEGDBpKkjz/+WEeOHNHDDz/sOBUQeJYvX642bdpo3759mjp1qtq2bes6EoBzQCGDE9ZaTZo0SVOnTtXq1av1xhtvKCwszHUsICCkpaWpdevWCg8P14IFC3TllVe6jgTgHLGGDE4YYzRx4kQ98cQTGjx4sNq1a6cDBw64jgX4NWutrLUqWrSoPv30U/3444+UMSBIUMjgTHh4uN566y0NGzZMM2fO1HXXXacjR464jgX4pbS0NHXp0kVDhgyRJDVu3Fhly5Z1nApAQaGQwblHH31UM2fOVMeOHVWsWDHXcQC/s2XLFjVp0kRjxoxhJBkIUqwhg19o0aKFWrRoIUn64Ycf9N133+mZZ57hrDGEvHnz5umOO+7Q4cOHNXnyZN1+++2uIwHwAUbI4Hc+/vhj9ezZU506ddKhQ4dcxwGc+fPPP9WyZUuVLFlSP/74I2UMCGIUMvidpKQkDRgwQJ999pkaNWqkdevWuY4EFKrs7GxJUoUKFTR+/HgtWrRItWrVcpwKgC9RyOB3jDHq1auXvvzyS23dulVxcXFavXq161hAoVi7dq0aNmyoWbNmSZLat2+vEiVKOE4FwNcoZPBbLVu21JIlS9S1a1ddeumlruMAPvfpp5+qQYMG+uOPP46PkgEIDRQy+LWqVavqzTffVFhYmP7880+1bt1aGzdudB0LKFBpaWn6xz/+oU6dOumKK67Q8uXLdcstt7iOBaAQUcgQMH7//XctWLBA9evX19SpU13HAQrMZ599pmHDhunZZ5/V3LlzValSJdeRABQyChkCxg033KBly5apWrVquv322/XEE0+wkSwClrVWycnJkqT4+HgtWrRIiYmJioiIcJwMgAsUMgSUSy65RAsWLFCPHj2UlJSkl156yXUkIM9SUlJ0zz33qG7dutq8ebOMMWrYsKHrWAAcYmNYBJyoqCgNGTJErVu3VlxcnCRp165duuCCC1SkCH9jwL/NmTNH999/v7Zt26aXXnpJ5cqVcx0JgB/g/14IWDfeeKNKliypjIwM3XTTTbrxxhu1ZcsW17GAHFlr1bNnTzVr1kzFihXT999/r969eys8nL+LAVDIEATCw8PVvXt3LVq0SHXq1NHYsWNlrXUdCziJMUZ79+5VQkKCli1bpquuusp1JAB+hEKGgGeM0YMPPqiffvpJl19+uTp37qxbb71Ve/bscR0NIe7o0aPq06ePli1bJkl67733NHz4cMXExDhOBsDfUMgQNKpXr665c+fqrbfe0u7du1W8eHHXkRDCFi9erAYNGujVV1/VjBkzJElhYWGOUwHwVxQyBJWwsDA98cQTWrhwoaKiorR//3517tyZzWRRaI4cOaJevXqpUaNG2rdvn7744gv17dvXdSwAfo5ChqB07GzL5cuXa/Lkybr88suVmJiojIwMx8kQ7EaOHKnExER17dpVq1atUqtWrVxHAhAAKGQIak2aNNGqVat04403qlevXqpfv76+++4717EQZP78808tXLhQkvTII49o7ty5GjlyJBcFB5BrFDIEvUqVKmnq1KmaPn26Dh48qFdffdV1JASJzMxMDRkyRJdddpk6d+6s7OxsRUVF6frrr3cdDUCAoZAhZLRp00arVq3S6NGjJUl//PGH3n33XWVmZroNhoA0d+5cxcXF6Z///KcaN26smTNnsjExgHzjtwdCSkxMzPGd0T/66CN1795dV155pWbNmuU4GQLJggUL1LRpU+3du1cTJ07UF198oUsuucR1LAABjEKGkNWnTx9NmTJFR48e1c0336xWrVpp9erVrmPBT6Wmpurrr7+WJF177bX64IMPtGbNGnXs2FHGGMfpAAQ6ChlCljFGt912m1atWqU33nhDCxYsUFJSkutY8DPp6ekaOnSoatSoodtvv10HDhyQMUZdu3ZVsWLFXMcDECQoZAh5UVFReuaZZ7Ru3brjC/7nz5+vF154QSkpKY7TwZWsrCyNGTNGNWvW1GOPPabatWtrzpw5io2NdR0NQBCikAFepUuXVqlSpSRJ8+bN04ABA1S1alW99tprOnjwoON0KGyrVq3SAw88oFKlSmnmzJn69ttv9be//c11LABBikIG5OCFF17QTz/9pCZNmqh3796qVq2a3n//fdex4EPZ2dmaNm2a+vXrJ0mqW7euvv/+ey1ZskQ33XQT68QA+BSFDDiNunXratq0aVq4cKHq1q2rvXv3SvLsPTVi4QhVGVJFRV4uoipDqmjcL+Mcp0VejBsnVakiFSkiVa5s9Y9/zFfdunV12223acyYMTp8+LAk6ZprrqGIASgUxlrrOsNZxcXF2SVLlriOgRCXnZ2tIkWKqNu73TR863Ap4v9vi46I1og2IxRfJ95dQOTKuHFSQoLk7Vxeh1ShwstKTKynO++8U+Hh4a7iAQgCxpil1tq4PD2GQgbkTfk3ymvb4W1/OV65RGVtfHJj4QdCnlSsmKktW/5auCpVskpOZjQMwLnLTyFjyhLIo+2Ht+d4fFPqJklSIPyRE4qWLFmi++67T1u25Pxrb/NmyhgAdyhkQB5VKlHptMcPHDigOnXq6NVXX9WWLVsKORlyMmPGDF177bW66qqrNHXqVMXG7svxfpVy/rECQKGgkAF51K95P0VHRJ90LDoiWv2a99OuXbtUpkwZ9enTR5UrV1br1q01efJkpaenO0obeqy1Wrx48fGF+WvWrNGuXbs0ZMgQbdmyRcOGlVL0yT8+RUdL3pMrAcAJ1pAB+TDul3Hq/XVvbUrdpEolKqlf834nLehfv369PvzwQ40ePVp//vmnfv75Z9WpU0cHDx5UTEwMZ+75wNatW/Wf//xHo0aN0i+//KIxY8bo/vvvV3p6uiIiIk76no8bJ/XuLW3a5BkZ69dPiud8DAAFhEX9gJ/JysrSggULdP3110uS4uPj9eOPP+quu+5Sp06ddMUVVzhOGPgOHDigNm3aaN68ebLWKi4uTg8++KDuvvtulShRwnU8ACGIRf2AnwkLCztexiTplltuUeXKldW/f3/VqVNHl19+uYYPH+4wYeDZtGmThg0bpsTERElSbGysLrjgAr344otavXq1Fi9erEcffZQyBiCgMEIGOLBjxw5NmjRJn376qa6++molJiYqIyNDTzzxhFq2bKkWLVpwzcQTLF++XBMnTtQXX3yhn3/+WZJUv359LV26lOlfAH6HKUsgAFlrZYzR6tWrdc011yg1NVWRkZFq1KiRmjZtqvvvv1/VqlVzHbPQZGdna+XKlZozZ44SEhJUtGhR9erVS4MGDVLjxo116623qnXr1qpZsyZlDIBfopABAS4jI0MLFizQF198oTlz5mjZsmX65ptv1KRJEy1atEgzZszQVVddpbi4OJUvX9513AKzZcsWffrpp1qwYIHmzp17/DJV8+fP13XXXaedO3cqMjJS559/vuOkAHB2AVPIjDEbJR2QlCUp82yhKWQIVampqYqOjlZERITeeustPfXUU8rOzpYklS9fXnFxcRo9erRKliyp/fv3Kzo6umAu++OD0xCttdq+fbtWr16tVatWaenSpbr33nvVokULff/997ruuutUpUoV3XDDDWratKmaNGmiypUrn/vXAgCFLD+FzOUF226w1u52+PqA3ztxYXqPHj300EMP6aefftKSJUu0ZMkSrV69+vh9nn76aY0dO1Y1atRQrVq1dNlll6l69erq3LmzJCk9PV2RkZFnf9FTL/aYnOz5XDprKTt69Ki2bNmizZs3a/Pmzapatar+/ve/a+fOnbr00kuVmpp6/L5lypRR06ZNJUlxcXHavn27ypQpk8vvDAAEF5cjZHG5LWSMkAFn9+WXX2rOnDn67bfftHr1aq1fv15Vq1bVunXrJEktW7bUokWLVLZsWZUsWVKlSpXSlVdeqf79+0uSPvjgA+3du1eP9O+v81JS/vL8B0qV0jvPPKP09HSlpqYqJSVFV155pZ588klJUtWqVbVx48aTHvPQQw9p5MiRstaqR48ex8tirVq1VL58edaAAQhKgTRl+YekFElW0nvW2hE53CdBUoIkVapUqUFycnLhhgQCXGZmpvbu3auLLrpIkvThhx9q2bJl2rlzp1JSUpSSkqJq1appwoQJkqQ6depo5cqVylLO++FkSwrzfhwTE6NSpUqpXbt2SkpKkiQ9++yzio2NVcWKFU96iz51W3wACHKBVMjKW2u3GmMukvSVpMettfNOd39GyADfS09PV0ZGhopedpnCcrgOZ3bFikr//XdFREQoLCwsh2cAAEgBtDGstXar9/1OSVMkNXSRA8D/i4yMVExMjMIGDFBOF3ss0r+/ihYtShkDAB8o9EJmjIkxxsQe+1hSS0krCzsHgNOIj5dGjJAqV5aM8bwfMYKLPQKAD7k4y7KMpCnexbzhksZba2c6yAHgdOLjKWAAUIgKvZBZazdIurKwXxcAAMBfcXFxAAAAxyhkAAAAjlHIAAAAHKOQAQAAOEYhAwAAcIxCBgAA4BiFDAAAwDEKGQAAgGMUMgAAAMcoZAAAAI5RyAAAAByjkAEAADhGIQMAAHCMQgYAAOAYhQwAAMAxChkAAIBjFDIAAADHKGQAAACOUcgAAAAco5ABAAA4RiEDAABwjEIGAADgGIUMAADAMQoZAACAYxQyAAAAxyhkAAAAjlHIAAAAHKOQAQAAOEYhAwAAcIxCBgAA4BiFDAAAwDEKGQAAgGMUMgAAAMcoZAAAAI5RyAAAAByjkAEAADhGIQMAAHCMQgYAAOAYhQwAAMAxChkAAIBjFDIAAADHKGQAAACOUcgAAAAco5ABAAA4RiEDAABwjEIGAADgGIUMAADAMQoZAACAYxQyAAAAxyhkAAAAjlHIAAAAHKOQAQAAOEYhAwAAcIxCBgAA4BiFDAAAwDEnhcwYc7MxZo0xZp0x5jkXGQAAAPxFoRcyY0yYpKGSbpFUW9LdxpjahZ0DAADAX7gYIWsoaZ21doO1Nl3SBEntHOQAAADwC+EOXrOCpM0nfL5F0tWn3skYkyApwfvpUWPMykLIBt+4UNJu1yGQL/zsAhs/v8DFzy6w1czrA1wUMpPDMfuXA9b+X3t3EzJVGYdh/LrRwtSiIgpTQQOpQIjCwBQitEVQZJvARSXRMssiiGrTJqhFRK0CMUvIjDAhiegDDVoEomlUZhBUmGUZRB8EUda/xUwg9jEzwvs+c5jrt5kzB87hhoeZued8PRuBjQBJ9lXVsqkOpqnh+HWXY9dtjl93OXbdlmTfqNu0OGV5BFh4wvsFwNcNckiSJI2FFoVsL7AkyeIkpwNrgZ0NckiSJI2FaT9lWVXHk6wH3gBmAJur6uCAzTZOfTJNIcevuxy7bnP8usux67aRxy9V/7h8S5IkSdPIJ/VLkiQ1ZiGTJElqbKwLmVMsdVeShUneTnIoycEkGxUU2CsAAANASURBVFpn0miSzEhyIMmrrbNoNEnOTrI9ySf9z+BVrTNpeEnu7X9vfpRkW5JZrTPpvyXZnOTYic9LTXJukreSfNp/PWfQfsa2kDnFUucdB+6rqkuB5cCdjl/nbAAOtQ6hU/IU8HpVXQJchuPYGUnmA3cDy6pqKb2b39a2TaUBngOuO2ndA8CuqloC7Oq//19jW8hwiqVOq6qjVbW/v/wzvR+E+W1TaVhJFgDXA5taZ9FokpwFXA08A1BVv1XVD21TaUQzgTOSzARm47M6x1pVvQN8f9LqNcCW/vIW4KZB+xnnQvZvUyz5g95BSRYBlwN72ibRCJ4E7gf+bB1EI7sI+A54tn/KeVOSOa1DaThV9RXwOHAYOAr8WFVvtk2lU3BBVR2F3gEK4PxBG4xzIRtqiiWNtyRzgZeBe6rqp9Z5NFiSG4BjVfVe6yw6JTOBK4Cnq+py4BeGOF2i8dC/1mgNsBi4EJiT5Ja2qTQdxrmQOcVSxyU5jV4Z21pVO1rn0dBWAjcm+YLepQKrkjzfNpJGcAQ4UlV/H5HeTq+gqRuuBT6vqu+q6ndgB7CicSaN7tsk8wD6r8cGbTDOhcwpljosSehdw3Koqp5onUfDq6oHq2pBVS2i97nbXVX+Q++IqvoG+DLJxf1Vq4GPG0bSaA4Dy5PM7n+PrsabMrpoJ7Cuv7wOeGXQBtM+ddKwTnGKJY2PlcCtwIdJ3u+ve6iqXmuYSZoUdwFb+39mPwNub5xHQ6qqPUm2A/vp3a1+AKdRGmtJtgHXAOclOQI8DDwGvJTkDnol++aB+3HqJEmSpLbG+ZSlJEnSRLCQSZIkNWYhkyRJasxCJkmS1JiFTJIkqTELmSRJUmMWMkmSpMYsZJImSpIrk3yQZFaSOUkOJlnaOpekyeaDYSVNnCSPALOAM+jN+/ho40iSJpyFTNLE6U8ptBf4FVhRVX80jiRpwnnKUtIkOheYC5xJ70iZJDXlETJJEyfJTuBFYDEwr6rWN44kacLNbB1AkqZTktuA41X1QpIZwLtJVlXV7tbZJE0uj5BJkiQ15jVkkiRJjVnIJEmSGrOQSZIkNWYhkyRJasxCJkmS1JiFTJIkqTELmSRJUmN/AR6mUzcEPd7aAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5489d9feb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pltplt.figure(figsize = (10,7))\n",
    "plt.plot(x_quad, y_quad, 'k--')\n",
    "plt.axis([0,10,0,30])\n",
    "plt.plot([1, 2, 3], [14, 9, 6], 'go')\n",
    "plt.plot([5, 7, 8],[6, 14, 21], 'bo')\n",
    "plt.plot(4, 5, 'ro')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Plotting Quadratic Equation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First testing your tensorflow is working or not  \n",
    "\n",
    "အရင်ဆုံး ခင်ဗျားတို့ရဲ့စက်ထဲမှာရှိတဲ့ tensorflow က အလုပ်လုပ်လို့ ရပြီလား test လုပ်ကြည့်ရအောင်"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lar/anaconda3/envs/py3.6.2/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hello = tf.constant(\"Hello, world!\")\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, world!'\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to show tensorboard demo  \n",
    "link is as follows:  \n",
    "https://www.tensorflow.org/programmers_guide/graph_viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensorflow Working Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lar/anaconda3/envs/py3.6.2/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Addition: 5\n"
     ]
    }
   ],
   "source": [
    "# build computational graph\n",
    "a = tf.placeholder(tf.int16)\n",
    "b = tf.placeholder(tf.int16)\n",
    "\n",
    "addition = tf.add(a, b)\n",
    "\n",
    "# initialize variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# create session and run the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print (\"Addition: %i\" % sess.run(addition, feed_dict={a: 2, b: 3}))\n",
    "\n",
    "# close session\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When I have time, I will show gradianet decsent calculation with python code\n",
    "\n",
    "# OR gate model with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32_ref>\n",
      "bias <tf.Variable 'Variable_1:0' shape=(1,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "'''\n",
    "Model Setting\n",
    "'''\n",
    "tf.set_random_seed(0)  # Setting random seed\n",
    "\n",
    "w = tf.Variable(tf.zeros([2, 1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "print(\"weight\",w)\n",
    "print(\"bias\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22355038]\n",
      " [0.9142595 ]\n",
      " [0.9142595 ]\n",
      " [0.99747425]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "t = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "y = tf.nn.sigmoid(tf.matmul(x, w) + b)\n",
    "\n",
    "cross_entropy = - tf.reduce_sum(t * tf.log(y) + (1 - t) * tf.log(1 - y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.to_float(tf.greater(y, 0.5)), t)\n",
    "\n",
    "'''\n",
    "Model learning\n",
    "'''\n",
    "# Training Data of OR gate\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = np.array([[0], [1], [1], [1]])\n",
    "\n",
    "# Initialization\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Learning\n",
    "for epoch in range(200):\n",
    "    sess.run(train_step, feed_dict={\n",
    "        x: X,\n",
    "        t: Y\n",
    "    })\n",
    "\n",
    "'''\n",
    "Classification\n",
    "'''\n",
    "classified = correct_prediction.eval(session=sess, feed_dict={\n",
    "    x: X,\n",
    "    t: Y\n",
    "})\n",
    "prob = y.eval(session=sess, feed_dict={\n",
    "    x: X\n",
    "})\n",
    "\n",
    "print (prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classified:\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "\n",
      "output probability:\n",
      "[[0.22355038]\n",
      " [0.9142595 ]\n",
      " [0.9142595 ]\n",
      " [0.99747425]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('classified:')\n",
    "print(classified)\n",
    "print()\n",
    "print('output probability:')\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Moons Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before reshape: (300,)\n",
      "[1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1\n",
      " 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0\n",
      " 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 0\n",
      " 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0\n",
      " 0 1 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0\n",
      " 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1\n",
      " 1 0 0 1]\n",
      "==========\n",
      "after reshape: (300, 1)\n",
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "'''\n",
    "Training Data, Test Data Preparation\n",
    "'''\n",
    "N = 300  # Data Size\n",
    "X, y = datasets.make_moons(N, noise=0.3)\n",
    "\n",
    "print(\"before reshape:\", y.shape)\n",
    "print(y)\n",
    "print(\"==========\")\n",
    "\n",
    "Y = y.reshape(N, 1)\n",
    "\n",
    "print(\"after reshape:\", Y.shape)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lar/anaconda3/envs/py3.6.2/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.95\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
    "\n",
    "\n",
    "'''\n",
    "Model Building\n",
    "'''\n",
    "num_hidden = 3  # Number of Dimension of Hidden Layer\n",
    "# num_hidden = 2\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "t = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "# Input - Hidden\n",
    "W = tf.Variable(tf.truncated_normal([2, num_hidden]))\n",
    "b = tf.Variable(tf.zeros([num_hidden]))\n",
    "h = tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "\n",
    "# Hidden - Output\n",
    "V = tf.Variable(tf.truncated_normal([num_hidden, 1]))\n",
    "c = tf.Variable(tf.zeros([1]))\n",
    "y = tf.nn.sigmoid(tf.matmul(h, V) + c)\n",
    "\n",
    "cross_entropy = - tf.reduce_sum(t * tf.log(y) + (1 - t) * tf.log(1 - y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.to_float(tf.greater(y, 0.5)), t)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "'''\n",
    "Model Learning\n",
    "'''\n",
    "batch_size = 20\n",
    "n_batches = N // batch_size\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(500):\n",
    "    X_, Y_ = shuffle(X_train, Y_train)\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: X_[start:end],\n",
    "            t: Y_[start:end]\n",
    "        })\n",
    "\n",
    "'''\n",
    "Evaluation\n",
    "'''\n",
    "accuracy_rate = accuracy.eval(session=sess, feed_dict={\n",
    "    x: X_test,\n",
    "    t: Y_test\n",
    "})\n",
    "print('accuracy: ', accuracy_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing with MNIST Orignial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lar/anaconda3/envs/py3.6.2/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 2.3021867  accuracy: 0.11525\n",
      "epoch: 1  loss: 2.3018122  accuracy: 0.11525\n",
      "epoch: 2  loss: 2.3014212  accuracy: 0.11525\n",
      "epoch: 3  loss: 2.3009894  accuracy: 0.11525\n",
      "epoch: 4  loss: 2.3004873  accuracy: 0.11525\n",
      "epoch: 5  loss: 2.299864  accuracy: 0.11525\n",
      "epoch: 6  loss: 2.2990499  accuracy: 0.11525\n",
      "epoch: 7  loss: 2.297917  accuracy: 0.11525\n",
      "epoch: 8  loss: 2.2962322  accuracy: 0.11525\n",
      "epoch: 9  loss: 2.2934604  accuracy: 0.118375\n",
      "epoch: 10  loss: 2.2881455  accuracy: 0.19625\n",
      "epoch: 11  loss: 2.2749128  accuracy: 0.285625\n",
      "epoch: 12  loss: 2.21967  accuracy: 0.275875\n",
      "epoch: 13  loss: 1.955585  accuracy: 0.236625\n",
      "epoch: 14  loss: 1.8271803  accuracy: 0.30775\n",
      "epoch: 15  loss: 1.3660227  accuracy: 0.4705\n",
      "epoch: 16  loss: 1.190868  accuracy: 0.548625\n",
      "epoch: 17  loss: 0.7621454  accuracy: 0.736\n",
      "epoch: 18  loss: 0.61233056  accuracy: 0.80725\n",
      "epoch: 19  loss: 0.550963  accuracy: 0.82975\n",
      "epoch: 20  loss: 0.5032972  accuracy: 0.850625\n",
      "epoch: 21  loss: 0.43840474  accuracy: 0.87525\n",
      "epoch: 22  loss: 0.45044068  accuracy: 0.86025\n",
      "epoch: 23  loss: 0.38614905  accuracy: 0.89\n",
      "epoch: 24  loss: 0.34379044  accuracy: 0.9035\n",
      "epoch: 25  loss: 0.33130926  accuracy: 0.901375\n",
      "epoch: 26  loss: 0.3084093  accuracy: 0.91175\n",
      "epoch: 27  loss: 0.2547863  accuracy: 0.9295\n",
      "epoch: 28  loss: 0.23108868  accuracy: 0.937375\n",
      "epoch: 29  loss: 0.24561225  accuracy: 0.92625\n",
      "epoch: 30  loss: 0.24268964  accuracy: 0.934\n",
      "epoch: 31  loss: 0.17968026  accuracy: 0.952\n",
      "epoch: 32  loss: 0.17272319  accuracy: 0.955375\n",
      "epoch: 33  loss: 0.14297959  accuracy: 0.963375\n",
      "epoch: 34  loss: 0.13577306  accuracy: 0.96525\n",
      "epoch: 35  loss: 0.13238029  accuracy: 0.96525\n",
      "epoch: 36  loss: 0.11342529  accuracy: 0.97175\n",
      "epoch: 37  loss: 0.10031071  accuracy: 0.978\n",
      "epoch: 38  loss: 0.9185948  accuracy: 0.729375\n",
      "epoch: 39  loss: 0.1901246  accuracy: 0.94975\n",
      "epoch: 40  loss: 0.12709151  accuracy: 0.968375\n",
      "epoch: 41  loss: 0.10361673  accuracy: 0.97625\n",
      "epoch: 42  loss: 0.088337004  accuracy: 0.981625\n",
      "epoch: 43  loss: 0.07555725  accuracy: 0.983375\n",
      "epoch: 44  loss: 0.066762045  accuracy: 0.986875\n",
      "epoch: 45  loss: 0.059748724  accuracy: 0.9885\n",
      "epoch: 46  loss: 0.052632667  accuracy: 0.989875\n",
      "epoch: 47  loss: 0.04780354  accuracy: 0.991\n",
      "epoch: 48  loss: 0.050886832  accuracy: 0.9885\n",
      "epoch: 49  loss: nan  accuracy: 0.094375\n",
      "epoch: 50  loss: nan  accuracy: 0.094375\n",
      "epoch: 51  loss: nan  accuracy: 0.094375\n",
      "epoch: 52  loss: nan  accuracy: 0.094375\n",
      "epoch: 53  loss: nan  accuracy: 0.094375\n",
      "epoch: 54  loss: nan  accuracy: 0.094375\n",
      "epoch: 55  loss: nan  accuracy: 0.094375\n",
      "epoch: 56  loss: nan  accuracy: 0.094375\n",
      "epoch: 57  loss: nan  accuracy: 0.094375\n",
      "epoch: 58  loss: nan  accuracy: 0.094375\n",
      "epoch: 59  loss: nan  accuracy: 0.094375\n",
      "epoch: 60  loss: nan  accuracy: 0.094375\n",
      "epoch: 61  loss: nan  accuracy: 0.094375\n",
      "epoch: 62  loss: nan  accuracy: 0.094375\n",
      "epoch: 63  loss: nan  accuracy: 0.094375\n",
      "epoch: 64  loss: nan  accuracy: 0.094375\n",
      "epoch: 65  loss: nan  accuracy: 0.094375\n",
      "epoch: 66  loss: nan  accuracy: 0.094375\n",
      "epoch: 67  loss: nan  accuracy: 0.094375\n",
      "epoch: 68  loss: nan  accuracy: 0.094375\n",
      "epoch: 69  loss: nan  accuracy: 0.094375\n",
      "epoch: 70  loss: nan  accuracy: 0.094375\n",
      "epoch: 71  loss: nan  accuracy: 0.094375\n",
      "epoch: 72  loss: nan  accuracy: 0.094375\n",
      "epoch: 73  loss: nan  accuracy: 0.094375\n",
      "epoch: 74  loss: nan  accuracy: 0.094375\n",
      "epoch: 75  loss: nan  accuracy: 0.094375\n",
      "epoch: 76  loss: nan  accuracy: 0.094375\n",
      "epoch: 77  loss: nan  accuracy: 0.094375\n",
      "epoch: 78  loss: nan  accuracy: 0.094375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "'''\n",
    "MNIST data preparation\n",
    "'''\n",
    "mnist = datasets.fetch_mldata('MNIST original', data_home='.')\n",
    "\n",
    "n = len(mnist.data)\n",
    "N = 10000  # We will use a part of MNIST dataset\n",
    "train_size = 0.8\n",
    "indices = np.random.permutation(range(n))[:N]  # Random number of image\n",
    "\n",
    "X = mnist.data[indices]\n",
    "y = mnist.target[indices]\n",
    "Y = np.eye(10)[y.astype(int)]  # 1-of-K \n",
    "\n",
    "X_train, X_test, Y_train, Y_test =\\\n",
    "    train_test_split(X, Y, train_size=train_size)\n",
    "\n",
    "'''\n",
    "Model Setting\n",
    "'''\n",
    "n_in = len(X[0])  # 784\n",
    "n_hidden = 200\n",
    "n_out = len(Y[0])  # 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, n_in])\n",
    "t = tf.placeholder(tf.float32, shape=[None, n_out])\n",
    "\n",
    "# Input - Hidden\n",
    "W0 = tf.Variable(tf.truncated_normal([n_in, n_hidden], stddev=0.01))\n",
    "b0 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h0 = tf.nn.relu(tf.matmul(x, W0) + b0)\n",
    "\n",
    "# Hidden - Hidden\n",
    "W1 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h1 = tf.nn.relu(tf.matmul(h0, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b2 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h2 = tf.nn.relu(tf.matmul(h1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b3 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h3 = tf.nn.relu(tf.matmul(h2, W3) + b3)\n",
    "\n",
    "# Hidden - Output\n",
    "W4 = tf.Variable(tf.truncated_normal([n_hidden, n_out], stddev=0.01))\n",
    "b4 = tf.Variable(tf.zeros([n_out]))\n",
    "y = tf.nn.softmax(tf.matmul(h3, W4) + b4)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(t * tf.log(y), axis=1))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "'''\n",
    "Model Learning\n",
    "'''\n",
    "epochs = 100\n",
    "batch_size = 200\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "n_batches = (int)(N * train_size) // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    X_, Y_ = shuffle(X_train, Y_train)\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: X_[start:end],\n",
    "            t: Y_[start:end]\n",
    "        })\n",
    "\n",
    "    # Calculating loss with Cross Entropy \n",
    "    loss = cross_entropy.eval(session=sess, feed_dict={\n",
    "        x: X_,\n",
    "        t: Y_\n",
    "    })\n",
    "    \n",
    "    # Evaluation with Accuracy\n",
    "    acc = accuracy.eval(session=sess, feed_dict={\n",
    "        x: X_,\n",
    "        t: Y_\n",
    "    })\n",
    "    print('epoch:', epoch, ' loss:', loss, ' accuracy:', acc)\n",
    "\n",
    "'''\n",
    "Prediction Accuracy\n",
    "'''\n",
    "accuracy_rate = accuracy.eval(session=sess, feed_dict={\n",
    "    x: X_test,\n",
    "    t: Y_test\n",
    "})\n",
    "print('accuracy: ', accuracy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "'''\n",
    "MNIST data preparation\n",
    "'''\n",
    "mnist = datasets.fetch_mldata('MNIST original', data_home='.')\n",
    "\n",
    "n = len(mnist.data)\n",
    "N = 10000  # We will use a part of MNIST dataset\n",
    "train_size = 0.8\n",
    "indices = np.random.permutation(range(n))[:N]  # Random number of image\n",
    "\n",
    "X = mnist.data[indices]\n",
    "y = mnist.target[indices]\n",
    "Y = np.eye(10)[y.astype(int)]  # 1-of-K \n",
    "\n",
    "X_train, X_test, Y_train, Y_test =\\\n",
    "    train_test_split(X, Y, train_size=train_size)\n",
    "\n",
    "'''\n",
    "Model Setting\n",
    "'''\n",
    "n_in = len(X[0])  # 784\n",
    "n_hidden = 200\n",
    "n_out = len(Y[0])  # 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, n_in])\n",
    "t = tf.placeholder(tf.float32, shape=[None, n_out])\n",
    "\n",
    "# Input - Hidden\n",
    "W0 = tf.Variable(tf.truncated_normal([n_in, n_hidden], stddev=0.01))\n",
    "b0 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h0 = tf.nn.relu(tf.matmul(x, W0) + b0)\n",
    "\n",
    "# Hidden - Hidden\n",
    "W1 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h1 = tf.nn.relu(tf.matmul(h0, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b2 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h2 = tf.nn.relu(tf.matmul(h1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b3 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h3 = tf.nn.relu(tf.matmul(h2, W3) + b3)\n",
    "\n",
    "# Hidden - Output\n",
    "W4 = tf.Variable(tf.truncated_normal([n_hidden, n_out], stddev=0.01))\n",
    "b4 = tf.Variable(tf.zeros([n_out]))\n",
    "y = tf.nn.softmax(tf.matmul(h3, W4) + b4)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(t * tf.log(y), axis=1))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "'''\n",
    "Model Learning\n",
    "'''\n",
    "epochs = 100\n",
    "batch_size = 200\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "n_batches = (int)(N * train_size) // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    X_, Y_ = shuffle(X_train, Y_train)\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: X_[start:end],\n",
    "            t: Y_[start:end]\n",
    "        })\n",
    "\n",
    "    # Calculating loss with Cross Entropy \n",
    "    loss = cross_entropy.eval(session=sess, feed_dict={\n",
    "        x: X_,\n",
    "        t: Y_\n",
    "    })\n",
    "    \n",
    "    # Evaluation with Accuracy\n",
    "    acc = accuracy.eval(session=sess, feed_dict={\n",
    "        x: X_,\n",
    "        t: Y_\n",
    "    })\n",
    "    print('epoch:', epoch, ' loss:', loss, ' accuracy:', acc)\n",
    "\n",
    "'''\n",
    "Prediction Accuracy\n",
    "'''\n",
    "accuracy_rate = accuracy.eval(session=sess, feed_dict={\n",
    "    x: X_test,\n",
    "    t: Y_test\n",
    "})\n",
    "print('accuracy: ', accuracy_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
